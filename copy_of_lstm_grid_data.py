# -*- coding: utf-8 -*-
"""Copy of LSTM_grid_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11B2PbWKsxG5MpS32alyvfe3ByAdg8pBt
"""

#Importing Libraries
import numpy as np
import pandas as pd
#import matplotlib.pyplot as plt

#Importing dataset
train = pd.read_csv('/mnt/fs/final_variation_grid_data.csv')
#clas = train['class']
#train.head()
#train.shape
#display(train)

train =train[~train.isin([np.nan, np.inf, -np.inf]).any(1)]

X=train.iloc[:,1:].values
y=train['class']

# one hot encode output variable
from tensorflow.keras.utils import to_categorical
y = to_categorical(y)

# Splitting the dataset into the Training set and Test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)



# Feature Scaling
#from sklearn.preprocessing import MinMaxScaler
#sc = MinMaxScaler()
#X_train = np.reshape(X_train,(-1,1))
#y_train = np.reshape(y_train,(-1,1))
#X_train = sc.fit_transform(X_train)
#y_train = sc.fit_transform(y_train)
#X_test =sc.fit_transform(X_test)
#y_test = np.reshape(y_test,(-1,1))
#y_test = sc.fit_transform(y_test)

X_train = np.reshape(X_train, (141828, 975,1))
X_test = np.reshape(X_test, (60784, 975,1))

# Importing the Keras libraries and packages for LSTM
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM

import pandas as pd
 #from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
 #from sklearn.preprocessing import StandardScaler   
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import activations
from tensorflow.keras import layers
from keras.models import Sequential
from keras.layers import Dense,Dropout,LSTM,BatchNormalization
from keras.callbacks import EarlyStopping
#import tensorflowjs as tfjs
from tensorflow.keras.callbacks import  ModelCheckpoint
from keras.callbacks import CSVLogger

model2 = tf.keras.models.Sequential([
     tf.keras.layers.LSTM(units =90,input_shape = X_train.shape[1:]),
     tf.keras.layers.BatchNormalization(),
     tf.keras.layers.Dense(50, activation='relu'),
     tf.keras.layers.Dropout(0.4),
     tf.keras.layers.Dense(171),
     tf.keras.layers.Activation(activations.softmax)

])
print(model2.summary())

# Compiling the RNN
model2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])

# checkpoint
checkpoint_path_1='/mnt/fs/model_history_log.csv'
checkpoint_path="/mnt/fs/lstm_grid_data_offset_with_var.h5"
keras_callbacks   = [
      EarlyStopping(monitor='val_loss', patience=25, mode='min', min_delta=0.0001),
      ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),
      CSVLogger(checkpoint_path_1,append=True)
]

# Fitting the RNN to the Training set
model2.fit(X_train, y_train,validation_data=(X_test, y_test), epochs = 150, batch_size = 32,verbose=1,callbacks=keras_callbacks)

train_accuracy1=model2.evaluate(X_train,y_train,verbose=0)
print(train_accuracy1[1])

test_accuracy1=model2.evaluate(X_test,y_test,verbose=0)
print(test_accuracy1[1])